{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaed7ae4",
   "metadata": {},
   "source": [
    "CE Synthetic Electropherogram Generator\n",
    "======================================\n",
    "\n",
    "This notebook generates synthetic capillary electrophoresis (CE) electropherograms.\n",
    "\n",
    "Outputs (in output folder)\n",
    "- signals/: M1_plXXXX.csv and M2_plXXXX.csv\n",
    "- labels_masks/: labels_mask_M{1|2}_plXXXX.csv\n",
    "- labels_centers/: labels_center_M{1|2}_plXXXX.csv\n",
    "- labels_map/: labels_map.csv + peak_positions_detailed.csv\n",
    "- plots/ (optional): per-channel and stacked plots\n",
    "\n",
    "Model rules\n",
    "- Template statistics are computed using molw >= 50 bp (templates can be noisy below 50 bp).\n",
    "- Channels 1â€“4: molw < 50 bp => baseline + normal noise only (no peaks).\n",
    "- Channel 5 (ladder): GeneScan 500 LIZ peaks at\n",
    "  35, 50, 75, 100, 139, 150, 160, 200, 250, 300, 340, 350, 400, 450, 490, 500 bp.\n",
    "- Baseline centering (optional): subtract a constant estimated only from molw < 50 bp,\n",
    "  which shifts the signal to baseline ~0 without changing noise texture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3a8b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many individuals (plants) to generate? [20]:  20\n",
      "Generate plots? (y/n) [n]:  y\n",
      "Seed (empty = random):  \n",
      "Output folder (empty = dataset_synthetic):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots: [############################] 240/240 (100.0%)\n",
      "\n",
      "Done.\n",
      "- out_dir: dataset_synthetic\n",
      "- signals_dir: dataset_synthetic/signals\n",
      "- labels_masks_dir: dataset_synthetic/labels_masks\n",
      "- labels_centers_dir: dataset_synthetic/labels_centers\n",
      "- labels_map_dir: dataset_synthetic/labels_map\n",
      "- plots_dir: dataset_synthetic/plots\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# =============================================================================\n",
    "# Config\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class GeneratorConfig:\n",
    "    # Core axis rules\n",
    "    template_stats_min_bp: float = 50.0   # ignore <50 bp when estimating template stats\n",
    "    prepeak_cutoff_bp: float = 50.0      # channels 1-4: <50 bp => baseline+noise only\n",
    "\n",
    "    # Ladder (channel 5): GeneScan 500 LIZ\n",
    "    liz500_peaks: Tuple[int, ...] = (35, 50, 75, 100, 139, 150, 160, 200, 250, 300, 340, 350, 400, 450, 490, 500)\n",
    "    ladder_noise_mult: float = 0.35\n",
    "    ladder_drift_mult: float = 0.015\n",
    "\n",
    "    # Baseline centering (DC offset removal only)\n",
    "    center_baseline: bool = True\n",
    "    center_q: int = 50  # percentile on region <50 bp (median recommended)\n",
    "\n",
    "    # Peak counts / placement\n",
    "    max_true_peaks: int = 12\n",
    "    max_total_events_per_channel: int = 28\n",
    "    p_sparse: float = 0.45\n",
    "    p_medium: float = 0.40\n",
    "    p_dense: float = 0.15\n",
    "    min_sep_bp: float = 1.1\n",
    "    p_overlap: float = 0.15\n",
    "\n",
    "    # Peak shape/amplitude\n",
    "    amp_floor: float = 80.0\n",
    "    sigma_min: float = 0.30\n",
    "    sigma_max: float = 2.20\n",
    "    tau_min: float = 0.25\n",
    "    tau_max: float = 2.60\n",
    "    p_left_tail: float = 0.08\n",
    "    amp_logn_sigma: float = 0.55\n",
    "\n",
    "    # Stutter\n",
    "    p_stutter: float = 0.28\n",
    "    p_forward_stutter: float = 0.06\n",
    "    p_double_step: float = 0.06\n",
    "    repeat_units: Tuple[int, ...] = (2, 3, 4, 5)\n",
    "\n",
    "    # Spurious peaks\n",
    "    p_spurious: float = 0.40\n",
    "    spurious_count_range: Tuple[int, int] = (1, 4)\n",
    "    spurious_amp_range: Tuple[float, float] = (30.0, 520.0)\n",
    "\n",
    "    # Noise\n",
    "    hf_noise_range: Tuple[float, float] = (0.45, 1.35)\n",
    "    corr_k_range: Tuple[int, int] = (6, 18)\n",
    "    hetero_range: Tuple[float, float] = (0.0010, 0.0035)\n",
    "    hetero_sqrt_cap: float = 300.0\n",
    "    het_winsor: Tuple[float, float] = (0.5, 99.5)\n",
    "    abs_noise_floor_range: Tuple[float, float] = (0.8, 2.2)\n",
    "\n",
    "    micro_white_range: Tuple[float, float] = (0.12, 0.33)\n",
    "    micro_ar_range: Tuple[float, float] = (0.08, 0.27)\n",
    "    micro_ar_phi_range: Tuple[float, float] = (0.35, 0.75)\n",
    "\n",
    "    # Baseline LF components\n",
    "    rw_sigma_factor: float = 0.014\n",
    "    drift_slope_factor: float = 0.03\n",
    "    lf_smooth_range: Tuple[int, int] = (31, 121)\n",
    "    lf_sine_count_range: Tuple[int, int] = (1, 3)\n",
    "    lf_period_range: Tuple[float, float] = (350.0, 1500.0)\n",
    "    lf_sine_amp_range: Tuple[float, float] = (0.2, 1.2)\n",
    "    lf_amp_factor: float = 0.50\n",
    "\n",
    "    baseline_lf_smooth: int = 121\n",
    "    baseline_lf_cap_frac_qlow: float = 0.70\n",
    "    baseline_lf_soft: float = 0.85\n",
    "\n",
    "    # Crosstalk\n",
    "    crosstalk_base: np.ndarray = field(default_factory=lambda: np.array([\n",
    "        [0.0, 0.028, 0.010, 0.006],\n",
    "        [0.018, 0.0, 0.028, 0.010],\n",
    "        [0.010, 0.018, 0.0, 0.028],\n",
    "        [0.006, 0.010, 0.018, 0.0],\n",
    "    ], dtype=float))\n",
    "    crosstalk_scale_range: Tuple[float, float] = (0.45, 0.80)\n",
    "    crosstalk_jitter: float = 0.25\n",
    "    p_pulldown: float = 0.12\n",
    "    pulldown_range: Tuple[float, float] = (0.001, 0.006)\n",
    "\n",
    "    # Saturation\n",
    "    sat_factor: float = 1.05\n",
    "    overload_softness: float = 1.0\n",
    "\n",
    "    # Simple sample shift per multiplex\n",
    "    mux_shift_max: int = 2\n",
    "\n",
    "    # molw randomization\n",
    "    molw_scale_range: Tuple[float, float] = (0.994, 1.006)\n",
    "    molw_shift_range: Tuple[float, float] = (-4.0, 4.0)\n",
    "    p_warp: float = 0.25\n",
    "    warp_strength_range: Tuple[float, float] = (-0.006, 0.006)\n",
    "    warp_kind_probs: Tuple[float, float] = (0.55, 0.45)  # quad, cubicS\n",
    "    p_molw_jitter: float = 0.65\n",
    "    molw_jitter_amp_range: Tuple[float, float] = (0.00, 0.25)\n",
    "    molw_jitter_smooth_range: Tuple[int, int] = (41, 121)\n",
    "\n",
    "    # Modes\n",
    "    modes: Tuple[str, ...] = (\"normal\", \"noisy\", \"clean\", \"saturated\")\n",
    "    mode_probs: Tuple[float, ...] = (0.60, 0.20, 0.10, 0.10)\n",
    "\n",
    "    # Labels\n",
    "    label_min_abs_height: float = 15.0\n",
    "    label_snr_k: float = 4.0\n",
    "    mask_sigma_mult: float = 2.0\n",
    "    mask_w_min: float = 1.5\n",
    "    mask_w_max: float = 6.0\n",
    "    include_mask_types: Tuple[str, ...] = (\"true\", \"stutter\", \"spurious\", \"crosstalk\")\n",
    "\n",
    "    # Legacy peak_positions_detailed.csv\n",
    "    legacy_peak_width_mult: float = 6.0\n",
    "    legacy_plant_peak_width_max_pb: float = 7.0\n",
    "    ampclass_t1: float = 900.0\n",
    "    ampclass_t2: float = 2570.0\n",
    "\n",
    "    # Plotting\n",
    "    plot_qlo: float = 0.5\n",
    "    plot_qhi: float = 99.5\n",
    "\n",
    "\n",
    "CFG = GeneratorConfig()\n",
    "\n",
    "# =============================================================================\n",
    "# Utilities\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def clamp(x: float, lo: float, hi: float) -> float:\n",
    "    return float(min(hi, max(lo, x)))\n",
    "\n",
    "def mad(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x, float)\n",
    "    med = np.median(x)\n",
    "    return 1.4826 * np.median(np.abs(x - med)) + 1e-12\n",
    "\n",
    "def smooth_noise(n: int, k: int) -> np.ndarray:\n",
    "    k = max(3, int(k))\n",
    "    z = np.random.normal(0.0, 1.0, n)\n",
    "    return np.convolve(z, np.ones(k) / k, mode=\"same\")\n",
    "\n",
    "def shift_series(y: np.ndarray, shift: int) -> np.ndarray:\n",
    "    y = np.asarray(y, float)\n",
    "    if shift == 0:\n",
    "        return y.copy()\n",
    "    out = np.roll(y, shift)\n",
    "    if shift > 0:\n",
    "        out[:shift] = out[shift]\n",
    "    else:\n",
    "        out[shift:] = out[shift - 1]\n",
    "    return out\n",
    "\n",
    "def resample_to_molw(molw_src: np.ndarray, y_src: np.ndarray, molw_dst: np.ndarray) -> np.ndarray:\n",
    "    molw_src = np.asarray(molw_src, float)\n",
    "    y_src = np.asarray(y_src, float)\n",
    "    molw_dst = np.asarray(molw_dst, float)\n",
    "    order = np.argsort(molw_src)\n",
    "    xs = molw_src[order]\n",
    "    ys = y_src[order]\n",
    "    return np.interp(molw_dst, xs, ys, left=ys[0], right=ys[-1])\n",
    "\n",
    "def nearest_index(x: np.ndarray, v: float) -> int:\n",
    "    return int(np.clip(np.searchsorted(x, v), 0, len(x) - 1))\n",
    "\n",
    "def ar1(n: int, phi: float, sigma: float) -> np.ndarray:\n",
    "    e = np.random.normal(0.0, sigma, n)\n",
    "    y = np.zeros(n)\n",
    "    for i in range(1, n):\n",
    "        y[i] = phi * y[i - 1] + e[i]\n",
    "    return y\n",
    "\n",
    "def winsor(x: np.ndarray, lo: float, hi: float) -> np.ndarray:\n",
    "    a, b = np.percentile(x, [lo, hi])\n",
    "    return np.clip(x, a, b)\n",
    "\n",
    "def span_p99_p1(y: np.ndarray) -> float:\n",
    "    y = np.asarray(y, float)\n",
    "    return float(np.percentile(y, 99) - np.percentile(y, 1))\n",
    "\n",
    "# =============================================================================\n",
    "# EMG peak\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    from scipy.special import erfcx  # type: ignore\n",
    "except Exception:\n",
    "    from math import erfc as _erfc_scalar\n",
    "    def erfcx(z):\n",
    "        z = np.asarray(z, dtype=float)\n",
    "        return np.exp(z * z) * np.vectorize(_erfc_scalar)(z)\n",
    "\n",
    "def emg_peak(x: np.ndarray, amp: float, mu: float, sigma: float, tau: float, left_tail: bool = False) -> np.ndarray:\n",
    "    x = np.asarray(x, float)\n",
    "    sigma = max(float(sigma), 1e-6)\n",
    "    tau = max(float(tau), 1e-6)\n",
    "    if left_tail:\n",
    "        x = (2.0 * mu) - x\n",
    "\n",
    "    lam = 1.0 / tau\n",
    "    a = (mu + lam * sigma * sigma - x) / (math.sqrt(2.0) * sigma)\n",
    "    expo = (lam / 2.0) * (2.0 * mu + lam * sigma * sigma - 2.0 * x)\n",
    "\n",
    "    with np.errstate(over=\"ignore\", under=\"ignore\", invalid=\"ignore\", divide=\"ignore\"):\n",
    "        y = (lam / 2.0) * np.exp(expo - a * a) * erfcx(a)\n",
    "\n",
    "    y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    m = float(y.max()) if y.size else 0.0\n",
    "    if m <= 0.0:\n",
    "        return np.zeros_like(x)\n",
    "    return (amp / m) * y\n",
    "\n",
    "def soft_saturate(y: np.ndarray, sat: float, softness: float) -> np.ndarray:\n",
    "    sat = max(float(sat), 1.0)\n",
    "    with np.errstate(over=\"ignore\", invalid=\"ignore\"):\n",
    "        z = sat * np.tanh(y / (sat * max(1e-6, softness)))\n",
    "    return np.nan_to_num(z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# =============================================================================\n",
    "# Template reading\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Template:\n",
    "    df: pd.DataFrame\n",
    "    molw: np.ndarray\n",
    "    min_bp: float\n",
    "    max_bp: float\n",
    "    ladder_noise: float\n",
    "    stats: Dict[int, Dict[str, float]]  # ch -> dict\n",
    "\n",
    "\n",
    "def read_template(csv_path: str, cfg: GeneratorConfig) -> Template:\n",
    "    df = pd.read_csv(csv_path, sep=\";\")\n",
    "    cols = [\"index\", \"molw\", \"channel_1\", \"channel_2\", \"channel_3\", \"channel_4\", \"channel_5\"]\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Template missing columns: {missing}\")\n",
    "\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    molw = df[\"molw\"].to_numpy(float)\n",
    "    good = molw >= cfg.template_stats_min_bp\n",
    "    if not np.any(good):\n",
    "        good = np.ones_like(molw, dtype=bool)\n",
    "\n",
    "    margin = max(40.0, 0.05 * (molw.max() - molw.min()))\n",
    "    min_bp = float(max(molw.min() + margin, cfg.template_stats_min_bp))\n",
    "    max_bp = float(molw.max() - margin)\n",
    "    if max_bp <= min_bp:\n",
    "        min_bp = float(max(np.min(molw[good]), cfg.template_stats_min_bp))\n",
    "        max_bp = float(np.max(molw[good]))\n",
    "\n",
    "    stats: Dict[int, Dict[str, float]] = {}\n",
    "    for ch in range(1, 5):\n",
    "        x = df[f\"channel_{ch}\"].to_numpy(float)[good]\n",
    "\n",
    "        q10 = np.quantile(x, 0.10)\n",
    "        low = x[x <= q10]\n",
    "        base_med = float(np.median(low)) if low.size else float(np.median(x))\n",
    "        base_noise = float(mad(low)) if low.size else float(mad(x))\n",
    "\n",
    "        q_low = float(np.quantile(x, 0.80))\n",
    "        q_high = float(np.quantile(x, 0.9995))\n",
    "\n",
    "        amp_cap = max(cfg.amp_floor, q_high) * 1.2\n",
    "        sat = max(cfg.amp_floor, q_high) * cfg.sat_factor\n",
    "\n",
    "        stats[ch] = dict(\n",
    "            base_med=base_med,\n",
    "            base_noise=max(base_noise, 1e-6),\n",
    "            q_low=q_low,\n",
    "            q_high=q_high,\n",
    "            amp_cap=amp_cap,\n",
    "            sat=sat,\n",
    "        )\n",
    "\n",
    "    ladder = df[\"channel_5\"].to_numpy(float)[good]\n",
    "    q10 = np.quantile(ladder, 0.10)\n",
    "    low = ladder[ladder <= q10]\n",
    "    ladder_noise = float(mad(low)) if low.size else float(mad(ladder))\n",
    "\n",
    "    return Template(df=df, molw=molw, min_bp=min_bp, max_bp=max_bp, ladder_noise=ladder_noise, stats=stats)\n",
    "\n",
    "# =============================================================================\n",
    "# Axis randomization\n",
    "# =============================================================================\n",
    "\n",
    "def enforce_monotonic(x: np.ndarray, min_step: float = 1e-6) -> np.ndarray:\n",
    "    x = np.asarray(x, float).copy()\n",
    "    for i in range(1, len(x)):\n",
    "        if x[i] <= x[i - 1]:\n",
    "            x[i] = x[i - 1] + min_step\n",
    "    return x\n",
    "\n",
    "def warp_molw(molw_base: np.ndarray, cfg: GeneratorConfig) -> Tuple[np.ndarray, Dict[str, float | str]]:\n",
    "    x = np.asarray(molw_base, float)\n",
    "    a = random.uniform(*cfg.molw_scale_range)\n",
    "    b = random.uniform(*cfg.molw_shift_range)\n",
    "    y = a * x + b\n",
    "\n",
    "    warp_kind = \"none\"\n",
    "    warp_k = 0.0\n",
    "    if random.random() < cfg.p_warp:\n",
    "        warp_kind = random.choices([\"quad\", \"cubicS\"], weights=cfg.warp_kind_probs, k=1)[0]\n",
    "        t = (x - x.mean()) / (x.max() - x.min() + 1e-9)\n",
    "        warp_k = random.uniform(*cfg.warp_strength_range)\n",
    "        if warp_kind == \"quad\":\n",
    "            y = y + (warp_k * (x.max() - x.min())) * (t * t - np.mean(t * t))\n",
    "        else:\n",
    "            y = y + (warp_k * (x.max() - x.min())) * (t * t * t - t)\n",
    "\n",
    "    jitter_amp = 0.0\n",
    "    if random.random() < cfg.p_molw_jitter:\n",
    "        jitter_amp = random.uniform(*cfg.molw_jitter_amp_range)\n",
    "        if jitter_amp > 0:\n",
    "            k_s = random.randint(*cfg.molw_jitter_smooth_range)\n",
    "            jit = smooth_noise(len(y), k_s)\n",
    "            jit = jit / (np.std(jit) + 1e-9)\n",
    "            y = y + jitter_amp * jit\n",
    "\n",
    "    y = enforce_monotonic(y)\n",
    "    meta = dict(molw_scale=a, molw_shift=b, warp_kind=warp_kind, warp_k=warp_k, molw_jitter_amp=jitter_amp)\n",
    "    return y, meta\n",
    "\n",
    "# =============================================================================\n",
    "# Baseline + noise\n",
    "# =============================================================================\n",
    "\n",
    "def baseline_components(molw: np.ndarray, base_med: float, base_noise: float, plant_offset: float,\n",
    "                        baseline_gain: float, mode: str, cfg: GeneratorConfig) -> np.ndarray:\n",
    "    n = len(molw)\n",
    "    x0 = float(molw.mean())\n",
    "    xr = float(molw.max() - molw.min() + 1e-9)\n",
    "\n",
    "    drift_mult, rw_mult = 1.0, 1.0\n",
    "    if mode == \"noisy\":\n",
    "        drift_mult, rw_mult = 1.35, 1.25\n",
    "    elif mode == \"clean\":\n",
    "        drift_mult, rw_mult = 0.75, 0.80\n",
    "    elif mode == \"saturated\":\n",
    "        drift_mult, rw_mult = 1.10, 1.10\n",
    "\n",
    "    offset = (base_med + plant_offset) + np.random.normal(0.0, 1.2 * base_noise)\n",
    "    slope = np.random.normal(0.0, drift_mult * cfg.drift_slope_factor * base_noise / xr)\n",
    "    drift = slope * (molw - x0)\n",
    "\n",
    "    rw = np.cumsum(np.random.normal(0.0, rw_mult * cfg.rw_sigma_factor * base_noise * baseline_gain, n))\n",
    "    rw -= rw.mean()\n",
    "\n",
    "    lf = smooth_noise(n, random.randint(*cfg.lf_smooth_range)) * (cfg.lf_amp_factor * base_noise * baseline_gain)\n",
    "\n",
    "    sines = np.zeros(n)\n",
    "    for _ in range(random.randint(*cfg.lf_sine_count_range)):\n",
    "        period = np.random.uniform(*cfg.lf_period_range)\n",
    "        phase = np.random.uniform(0, 2 * math.pi)\n",
    "        amp = np.random.uniform(*cfg.lf_sine_amp_range) * base_noise * baseline_gain\n",
    "        sines += amp * np.sin(2 * math.pi * (molw - molw.min()) / period + phase)\n",
    "\n",
    "    base = offset + drift + rw + lf + sines\n",
    "    return np.nan_to_num(base, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def limit_slow_baseline(base: np.ndarray, q_low: float, cfg: GeneratorConfig) -> np.ndarray:\n",
    "    n = len(base)\n",
    "    k = min(cfg.baseline_lf_smooth, max(9, n // 10))\n",
    "    slow = np.convolve(base, np.ones(k) / k, mode=\"same\")\n",
    "    fast = base - slow\n",
    "    amp = np.percentile(slow, 95) - np.percentile(slow, 5)\n",
    "    cap = cfg.baseline_lf_cap_frac_qlow * max(1.0, float(q_low))\n",
    "    if amp <= cap or amp <= 1e-9:\n",
    "        return base\n",
    "    scale = (cap / amp) ** cfg.baseline_lf_soft\n",
    "    slow2 = (slow - slow.mean()) * scale + slow.mean()\n",
    "    return np.nan_to_num(slow2 + fast, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def micro_texture(n: int, base_noise: float, abs_floor: float, mode: str, cfg: GeneratorConfig) -> np.ndarray:\n",
    "    w_lo, w_hi = cfg.micro_white_range\n",
    "    a_lo, a_hi = cfg.micro_ar_range\n",
    "    if mode == \"noisy\":\n",
    "        w_hi *= 1.25\n",
    "        a_hi *= 1.25\n",
    "    elif mode == \"clean\":\n",
    "        w_hi *= 0.75\n",
    "        a_hi *= 0.75\n",
    "\n",
    "    w_sigma = max(np.random.uniform(w_lo, w_hi) * base_noise, 0.25 * abs_floor)\n",
    "    a_sigma = max(np.random.uniform(a_lo, a_hi) * base_noise, 0.25 * abs_floor)\n",
    "\n",
    "    white = np.random.normal(0.0, w_sigma, n)\n",
    "    phi = np.random.uniform(*cfg.micro_ar_phi_range)\n",
    "    ar = ar1(n, phi, a_sigma)\n",
    "    return np.nan_to_num(white + ar, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def add_noise(base_noise: float, signal: np.ndarray, noise_gain: float, mode: str, cfg: GeneratorConfig) -> np.ndarray:\n",
    "    n = len(signal)\n",
    "\n",
    "    abs_floor = random.uniform(*cfg.abs_noise_floor_range)\n",
    "    if mode == \"noisy\":\n",
    "        abs_floor *= 1.2\n",
    "    elif mode == \"clean\":\n",
    "        abs_floor *= 0.8\n",
    "\n",
    "    hf_lo, hf_hi = cfg.hf_noise_range\n",
    "    if mode == \"noisy\":\n",
    "        hf_hi *= 1.35\n",
    "    elif mode == \"clean\":\n",
    "        hf_hi *= 0.80\n",
    "\n",
    "    hf_sigma = np.random.uniform(hf_lo, hf_hi) * base_noise * noise_gain\n",
    "    hf_sigma = max(hf_sigma, abs_floor)\n",
    "\n",
    "    white = np.random.normal(0.0, hf_sigma, n)\n",
    "    corr = smooth_noise(n, k=random.randint(*cfg.corr_k_range)) * (0.55 * hf_sigma)\n",
    "\n",
    "    hetero = np.random.uniform(*cfg.hetero_range) * noise_gain\n",
    "    s = np.sqrt(np.maximum(np.abs(signal), 0.0))\n",
    "    s = np.clip(s, 0.0, cfg.hetero_sqrt_cap)\n",
    "    het = winsor(np.random.normal(0.0, hetero * s, n), *cfg.het_winsor)\n",
    "\n",
    "    y = white + corr + het + micro_texture(n, base_noise, abs_floor, mode, cfg)\n",
    "    return np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# =============================================================================\n",
    "# Peak sampling helpers\n",
    "# =============================================================================\n",
    "\n",
    "def choose_mode(cfg: GeneratorConfig) -> str:\n",
    "    return random.choices(cfg.modes, weights=cfg.mode_probs, k=1)[0]\n",
    "\n",
    "def choose_peak_count(cfg: GeneratorConfig) -> int:\n",
    "    r = random.random()\n",
    "    if r < cfg.p_sparse:\n",
    "        rr = random.random()\n",
    "        return 0 if rr < 0.10 else (1 if rr < 0.55 else 2)\n",
    "    if r < cfg.p_sparse + cfg.p_medium:\n",
    "        return int(np.clip(np.random.poisson(5), 3, 8))\n",
    "    return int(np.clip(np.random.poisson(13), 9, 20))\n",
    "\n",
    "def sample_peak_centers(count: int, min_bp: float, max_bp: float, cfg: GeneratorConfig) -> List[float]:\n",
    "    centers: List[float] = []\n",
    "    tries = 0\n",
    "    while len(centers) < count and tries < 7000:\n",
    "        tries += 1\n",
    "        mu = random.uniform(min_bp, max_bp)\n",
    "        allow = (random.random() < cfg.p_overlap)\n",
    "        if allow or all(abs(mu - c) >= cfg.min_sep_bp for c in centers):\n",
    "            centers.append(mu)\n",
    "    while len(centers) < count:\n",
    "        centers.append(random.uniform(min_bp, max_bp))\n",
    "    centers.sort()\n",
    "    return centers\n",
    "\n",
    "def dropout_prob(q_low: float, x: float, cfg: GeneratorConfig) -> float:\n",
    "    mid = max(cfg.amp_floor, q_low) * 0.9\n",
    "    scale = max(1.0, mid * 0.30)\n",
    "    z = (mid - x) / scale\n",
    "    if z >= 0:\n",
    "        ez = math.exp(-z)\n",
    "        return 1 / (1 + ez)\n",
    "    ez = math.exp(z)\n",
    "    return ez / (1 + ez)\n",
    "\n",
    "def stutter_ratio(parent_amp: float, frac: float, cfg: GeneratorConfig) -> float:\n",
    "    mean = 0.05 + 0.10 * frac + (-0.025) * math.log(max(parent_amp, 1.0))\n",
    "    mean = float(np.clip(mean, 0.02, 0.30))\n",
    "    r = np.random.normal(mean, 0.03)\n",
    "    return float(np.clip(r, 0.01, 0.35))\n",
    "\n",
    "# =============================================================================\n",
    "# Crosstalk\n",
    "# =============================================================================\n",
    "\n",
    "def sample_crosstalk_matrix(cfg: GeneratorConfig) -> np.ndarray:\n",
    "    M = np.array(cfg.crosstalk_base, float)\n",
    "    M *= random.uniform(*cfg.crosstalk_scale_range)\n",
    "    M *= (1.0 + np.random.normal(0.0, cfg.crosstalk_jitter, M.shape))\n",
    "    M = np.clip(M, 0.0, None)\n",
    "\n",
    "    if random.random() < cfg.p_pulldown:\n",
    "        for _ in range(random.randint(1, 3)):\n",
    "            i, j = random.randint(0, 3), random.randint(0, 3)\n",
    "            if i != j:\n",
    "                M[i, j] = -random.uniform(*cfg.pulldown_range)\n",
    "\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "    return M\n",
    "\n",
    "def apply_crosstalk(peak_comp: Dict[str, np.ndarray], sat_levels: Dict[str, float],\n",
    "                    M: np.ndarray, cfg: GeneratorConfig) -> Tuple[Dict[str, np.ndarray], List[Tuple[str, str, float]]]:\n",
    "    chs = [f\"channel_{i}\" for i in range(1, 5)]\n",
    "    out = {ch: peak_comp[ch].copy() for ch in chs}\n",
    "    used: List[Tuple[str, str, float]] = []\n",
    "\n",
    "    sat_peaks = {ch: soft_saturate(peak_comp[ch], sat_levels[ch], cfg.overload_softness) for ch in chs}\n",
    "\n",
    "    for i, src in enumerate(chs):\n",
    "        for j, tgt in enumerate(chs):\n",
    "            if i == j:\n",
    "                continue\n",
    "            coef = float(M[i, j])\n",
    "            if abs(coef) < 1e-8:\n",
    "                continue\n",
    "            out[tgt] += coef * sat_peaks[src]\n",
    "            used.append((src, tgt, coef))\n",
    "\n",
    "    for ch in chs:\n",
    "        out[ch] = np.nan_to_num(out[ch], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    return out, used\n",
    "\n",
    "# =============================================================================\n",
    "# Labels\n",
    "# =============================================================================\n",
    "\n",
    "def passes_label_filter(event: Dict, cfg: GeneratorConfig) -> bool:\n",
    "    amp = float(event.get(\"peak_height\", 0.0))\n",
    "    bn = float(event.get(\"base_noise\", 0.0))\n",
    "    thr = max(cfg.label_min_abs_height, cfg.label_snr_k * bn)\n",
    "    return amp >= thr\n",
    "\n",
    "def build_dense_mask(molw: np.ndarray, events_out_axis: List[Dict], filename: str, cfg: GeneratorConfig) -> pd.DataFrame:\n",
    "    df = pd.DataFrame({\"molw\": molw})\n",
    "    for ch in range(1, 5):\n",
    "        df[f\"label_channel_{ch}\"] = 0\n",
    "\n",
    "    for e in events_out_axis:\n",
    "        if e[\"filename\"] != filename:\n",
    "            continue\n",
    "        if e.get(\"peak_type\") not in cfg.include_mask_types:\n",
    "            continue\n",
    "        if not passes_label_filter(e, cfg):\n",
    "            continue\n",
    "\n",
    "        ch = int(e[\"channel\"].split(\"_\")[1])\n",
    "        mu = float(e[\"peak_center_molw\"])\n",
    "        sigma = float(e.get(\"sigma\", 0.0))\n",
    "        w = cfg.mask_sigma_mult * sigma if sigma > 0 else cfg.mask_w_min\n",
    "        w = clamp(w, cfg.mask_w_min, cfg.mask_w_max)\n",
    "\n",
    "        df.loc[np.abs(molw - mu) <= w, f\"label_channel_{ch}\"] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_center_labels(molw: np.ndarray, events_out_axis: List[Dict], filename: str, cfg: GeneratorConfig) -> pd.DataFrame:\n",
    "    df = pd.DataFrame({\"molw\": molw})\n",
    "    for ch in range(1, 5):\n",
    "        df[f\"center_channel_{ch}\"] = 0\n",
    "\n",
    "    for e in events_out_axis:\n",
    "        if e[\"filename\"] != filename:\n",
    "            continue\n",
    "        if e.get(\"peak_type\") not in cfg.include_mask_types:\n",
    "            continue\n",
    "        if not passes_label_filter(e, cfg):\n",
    "            continue\n",
    "\n",
    "        ch = int(e[\"channel\"].split(\"_\")[1])\n",
    "        mu = float(e[\"peak_center_molw\"])\n",
    "        idx = nearest_index(molw, mu)\n",
    "        df.loc[idx, f\"center_channel_{ch}\"] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "# =============================================================================\n",
    "# Baseline centering (DC only)\n",
    "# =============================================================================\n",
    "\n",
    "def center_baseline_pre50(y: np.ndarray, molw: np.ndarray, cutoff: float, q: int) -> np.ndarray:\n",
    "    y = np.asarray(y, float).copy()\n",
    "    m = np.asarray(molw, float) < float(cutoff)\n",
    "    ref = float(np.percentile(y[m], q)) if np.any(m) else float(np.percentile(y, q))\n",
    "    return y - ref\n",
    "\n",
    "# =============================================================================\n",
    "# Ladder\n",
    "# =============================================================================\n",
    "\n",
    "def generate_liz500_ladder(molw_base: np.ndarray, molw_out: np.ndarray, ladder_noise: float, mux_shift: int,\n",
    "                           cfg: GeneratorConfig) -> np.ndarray:\n",
    "    x = np.asarray(molw_base, float)\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    base_sigma = np.random.uniform(0.35, 0.75)\n",
    "    base_tau = np.random.uniform(0.25, 0.65)\n",
    "\n",
    "    for p in cfg.liz500_peaks:\n",
    "        if p < float(x.min()) or p > float(x.max()):\n",
    "            continue\n",
    "        t = (p - 250.0) / 250.0\n",
    "        profile = 1.0 - 0.15 * (t * t)\n",
    "        amp = 12000.0 * profile * np.random.uniform(0.85, 1.15)\n",
    "\n",
    "        sigma = base_sigma * np.random.uniform(0.85, 1.15)\n",
    "        tau = base_tau * np.random.uniform(0.85, 1.15)\n",
    "        y += emg_peak(x, float(amp), float(p), float(sigma), float(tau), left_tail=False)\n",
    "\n",
    "    x0 = float(x.mean())\n",
    "    xr = float(x.max() - x.min() + 1e-9)\n",
    "    drift = np.random.normal(0.0, cfg.ladder_drift_mult * ladder_noise / xr) * (x - x0)\n",
    "    base = np.random.normal(0.0, cfg.ladder_noise_mult * ladder_noise, size=y.shape)\n",
    "\n",
    "    y = y + drift + base\n",
    "    y = shift_series(np.nan_to_num(y), mux_shift)\n",
    "    return resample_to_molw(x, y, np.asarray(molw_out, float))\n",
    "\n",
    "# =============================================================================\n",
    "# peak_positions_detailed (legacy)\n",
    "# =============================================================================\n",
    "\n",
    "def amp_class(amplitude: float, cfg: GeneratorConfig) -> str:\n",
    "    if amplitude < cfg.ampclass_t1:\n",
    "        return \"low\"\n",
    "    if amplitude < cfg.ampclass_t2:\n",
    "        return \"mid\"\n",
    "    return \"high\"\n",
    "\n",
    "def build_peak_positions_detailed(rows: List[Dict]) -> pd.DataFrame:\n",
    "    cols = [\n",
    "        \"plant_id\", \"plant_id_str\", \"multiplex\", \"channel\", \"marker_id\", \"peak_kind\", \"peak_index\",\n",
    "        \"mu_pb\", \"sigma_pb\", \"peak_width_pb\", \"amplitude\", \"amp_class\", \"plant_peak_width_max_pb\"\n",
    "    ]\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    group_cols = [\"plant_id_str\", \"multiplex\", \"channel\", \"peak_kind\"]\n",
    "    df = df.sort_values(group_cols + [\"mu_pb\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "    df[\"peak_index\"] = df.groupby(group_cols).cumcount() + 1\n",
    "    return df[cols]\n",
    "\n",
    "# =============================================================================\n",
    "# Plotting (optional)\n",
    "# =============================================================================\n",
    "\n",
    "def robust_ylim(ax, y, qlo=0.5, qhi=99.5):\n",
    "    y = np.asarray(y, float)\n",
    "    y = y[np.isfinite(y)]\n",
    "    if y.size == 0:\n",
    "        return\n",
    "    lo = np.percentile(y, qlo)\n",
    "    hi = np.percentile(y, qhi)\n",
    "    pad = 0.05 * (hi - lo) if hi > lo else 1.0\n",
    "    ax.set_ylim(lo - pad, hi + pad)\n",
    "\n",
    "def plot_channel(df: pd.DataFrame, out_path: str, col: str, qlo: float, qhi: float):\n",
    "    x = df[\"molw\"].to_numpy(float)\n",
    "    y = df[col].to_numpy(float)\n",
    "    fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.plot(x, y, lw=0.7)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    ax.set_xlabel(\"molw (bp)\")\n",
    "    ax.set_ylabel(col)\n",
    "    ax.set_xlim(float(x.min()), float(x.max()))\n",
    "    robust_ylim(ax, y, qlo, qhi)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=140)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_stacked(df: pd.DataFrame, out_path: str, qlo: float, qhi: float):\n",
    "    x = df[\"molw\"].to_numpy(float)\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(10, 8), sharex=True)\n",
    "    fig.subplots_adjust(hspace=0.35)\n",
    "    for i in range(1, 6):\n",
    "        col = f\"channel_{i}\"\n",
    "        y = df[col].to_numpy(float)\n",
    "        ax = axes[i - 1]\n",
    "        ax.plot(x, y, lw=0.7)\n",
    "        ax.set_ylabel(col, fontsize=8)\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        robust_ylim(ax, y, qlo, qhi)\n",
    "    axes[-1].set_xlabel(\"molw (bp)\")\n",
    "    axes[-1].set_xlim(float(x.min()), float(x.max()))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "def progress(done: int, total: int, width: int = 28, label: str = \"Generating plots\"):\n",
    "    frac = done / total if total else 1.0\n",
    "    filled = int(width * frac)\n",
    "    bar = \"#\" * filled + \"-\" * (width - filled)\n",
    "    print(f\"\\r{label}: [{bar}] {done}/{total} ({100*frac:5.1f}%)\", end=\"\", flush=True)\n",
    "    if done >= total:\n",
    "        print(\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# Main generator\n",
    "# =============================================================================\n",
    "\n",
    "def generate_dataset(\n",
    "    template_m1_path: str,\n",
    "    template_m2_path: str,\n",
    "    n_plants: int,\n",
    "    out_dir: str,\n",
    "    cfg: GeneratorConfig,\n",
    "    make_plots: bool = False,\n",
    "    seed: int | None = None,\n",
    ") -> Dict[str, str | None]:\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    ensure_dir(out_dir)\n",
    "    signals_dir = os.path.join(out_dir, \"signals\")\n",
    "    masks_dir = os.path.join(out_dir, \"labels_masks\")\n",
    "    centers_dir = os.path.join(out_dir, \"labels_centers\")\n",
    "    map_dir = os.path.join(out_dir, \"labels_map\")\n",
    "    for d in (signals_dir, masks_dir, centers_dir, map_dir):\n",
    "        ensure_dir(d)\n",
    "\n",
    "    plots_root = os.path.join(out_dir, \"plots\")\n",
    "    stacked_dir = os.path.join(plots_root, \"stacked\")\n",
    "    by_channel_dir = os.path.join(plots_root, \"by_channel\")\n",
    "    if make_plots:\n",
    "        ensure_dir(stacked_dir)\n",
    "        ensure_dir(by_channel_dir)\n",
    "        total_plots = n_plants * 2 * 6\n",
    "        done_plots = 0\n",
    "\n",
    "    tpl1 = read_template(template_m1_path, cfg)\n",
    "    tpl2 = read_template(template_m2_path, cfg)\n",
    "\n",
    "    labels_map_rows: List[Dict] = []\n",
    "    legacy_rows: List[Dict] = []\n",
    "\n",
    "    for plant_i in range(1, n_plants + 1):\n",
    "        plant_id = int(plant_i)\n",
    "        plant_id_str = int(plant_i)      # legacy example uses non-padded ints\n",
    "        plant_tag = f\"pl{plant_i:04d}\"\n",
    "\n",
    "        plant_gain = clamp(np.exp(np.random.normal(0.0, 0.18)), 0.6, 1.8)\n",
    "        plant_noise_gain = clamp(np.exp(np.random.normal(0.0, 0.14)), 0.7, 1.8)\n",
    "        plant_baseline_gain = clamp(np.exp(np.random.normal(0.0, 0.12)), 0.7, 1.6)\n",
    "        plant_offset = float(np.random.normal(0.0, 12.0))\n",
    "\n",
    "        corr = 0.45\n",
    "        C = (1 - corr) * np.eye(4) + corr * np.ones((4, 4))\n",
    "        L = np.linalg.cholesky(C)\n",
    "        z = L @ np.random.normal(0.0, 0.16, 4)\n",
    "        ch_gain = np.exp(z)\n",
    "        ch_gain = ch_gain / np.mean(ch_gain)\n",
    "\n",
    "        CT = sample_crosstalk_matrix(cfg)\n",
    "\n",
    "        for mux_idx, (mux_name, tpl) in enumerate([(\"M1\", tpl1), (\"M2\", tpl2)], start=1):\n",
    "            mode = choose_mode(cfg)\n",
    "            mux_gain = clamp(np.exp(np.random.normal(0.0, 0.10)), 0.75, 1.35)\n",
    "            mux_noise_gain = clamp(np.exp(np.random.normal(0.0, 0.08)), 0.75, 1.35)\n",
    "            mux_shift = random.randint(-cfg.mux_shift_max, cfg.mux_shift_max)\n",
    "\n",
    "            filename = f\"{mux_name}_{plant_tag}.csv\"\n",
    "\n",
    "            molw_base = tpl.molw\n",
    "            molw_out, molw_meta = warp_molw(molw_base, cfg)\n",
    "            molw_out = np.asarray(molw_out, float)\n",
    "            pre_mask = molw_out < cfg.prepeak_cutoff_bp\n",
    "\n",
    "            base_by_ch: Dict[str, np.ndarray] = {}\n",
    "            peaks_by_ch: Dict[str, np.ndarray] = {}\n",
    "            sat_levels: Dict[str, float] = {}\n",
    "            events: List[Dict] = []\n",
    "\n",
    "            # --- build baseline+peaks on base axis for channels 1..4 ---\n",
    "            for ch in range(1, 5):\n",
    "                ch_name = f\"channel_{ch}\"\n",
    "                gain = plant_gain * float(ch_gain[ch - 1]) * mux_gain\n",
    "                st = tpl.stats[ch]\n",
    "\n",
    "                base = baseline_components(molw_base, st[\"base_med\"], st[\"base_noise\"],\n",
    "                                          plant_offset, plant_baseline_gain, mode, cfg)\n",
    "                base = limit_slow_baseline(base, st[\"q_low\"], cfg)\n",
    "\n",
    "                peaks = np.zeros_like(molw_base)\n",
    "                evs: List[Dict] = []\n",
    "\n",
    "                n_true = choose_peak_count(cfg)\n",
    "                centers = sample_peak_centers(n_true, tpl.min_bp, tpl.max_bp, cfg)\n",
    "                for mu in centers:\n",
    "                    if sum(1 for e in evs if e.get(\"peak_type\") == \"true\") >= cfg.max_true_peaks:\n",
    "                        break\n",
    "                    if len(evs) >= cfg.max_total_events_per_channel:\n",
    "                        break\n",
    "\n",
    "                    frac = (mu - tpl.min_bp) / max(1e-9, (tpl.max_bp - tpl.min_bp))\n",
    "                    q_low = st[\"q_low\"]\n",
    "                    q_high = max(max(cfg.amp_floor, q_low) * 1.2, st[\"q_high\"])\n",
    "                    amp_cap = max(q_high, st[\"amp_cap\"])\n",
    "\n",
    "                    amp = math.exp(np.random.uniform(math.log(max(cfg.amp_floor, q_low) + 1e-9),\n",
    "                                                     math.log(q_high + 1e-9)))\n",
    "                    amp *= math.exp(np.random.normal(0.0, cfg.amp_logn_sigma))\n",
    "                    amp *= gain\n",
    "                    amp = float(np.clip(amp, cfg.amp_floor, amp_cap))\n",
    "\n",
    "                    decayed = amp * math.exp(-np.random.uniform(0.0, 1.1) * frac)\n",
    "                    if random.random() < dropout_prob(q_low, decayed, cfg):\n",
    "                        continue\n",
    "\n",
    "                    sigma = float(np.clip(np.random.uniform(cfg.sigma_min, cfg.sigma_max), cfg.sigma_min, cfg.sigma_max))\n",
    "                    tau = float(np.random.uniform(cfg.tau_min, cfg.tau_max))\n",
    "                    left = (random.random() < cfg.p_left_tail)\n",
    "\n",
    "                    peaks += emg_peak(molw_base, amp, mu, sigma, tau, left_tail=left)\n",
    "                    evs.append(dict(\n",
    "                        filename=filename, channel=ch_name,\n",
    "                        peak_center_molw=float(mu), peak_height=float(amp),\n",
    "                        peak_type=\"true\", sigma=float(sigma), tau=float(tau),\n",
    "                        base_noise=float(st[\"base_noise\"]),\n",
    "                    ))\n",
    "\n",
    "                    # stutter\n",
    "                    if random.random() < cfg.p_stutter and (len(evs) + 2) <= cfg.max_total_events_per_channel:\n",
    "                        ru = random.choice(cfg.repeat_units)\n",
    "                        if random.random() < cfg.p_double_step:\n",
    "                            ru *= 2\n",
    "                        shifts = [-ru]\n",
    "                        if random.random() < cfg.p_forward_stutter:\n",
    "                            shifts.append(ru)\n",
    "\n",
    "                        for sh in shifts:\n",
    "                            if len(evs) >= cfg.max_total_events_per_channel:\n",
    "                                break\n",
    "                            mu_s = mu + float(sh)\n",
    "                            if not (tpl.min_bp <= mu_s <= tpl.max_bp):\n",
    "                                continue\n",
    "                            ratio = stutter_ratio(amp, frac, cfg)\n",
    "                            amp_s = amp * ratio\n",
    "                            sigma_s = max(cfg.sigma_min, sigma * np.random.uniform(0.85, 1.10))\n",
    "                            tau_s = max(cfg.tau_min, tau * np.random.uniform(0.90, 1.15))\n",
    "                            peaks += emg_peak(molw_base, amp_s, mu_s, sigma_s, tau_s, left_tail=left)\n",
    "                            evs.append(dict(\n",
    "                                filename=filename, channel=ch_name,\n",
    "                                peak_center_molw=float(mu_s), peak_height=float(amp_s),\n",
    "                                peak_type=\"stutter\", sigma=float(sigma_s), tau=float(tau_s),\n",
    "                                base_noise=float(st[\"base_noise\"]),\n",
    "                            ))\n",
    "\n",
    "                # spurious peaks\n",
    "                if random.random() < cfg.p_spurious:\n",
    "                    for mu in sample_peak_centers(random.randint(*cfg.spurious_count_range), tpl.min_bp, tpl.max_bp, cfg):\n",
    "                        if len(evs) >= cfg.max_total_events_per_channel:\n",
    "                            break\n",
    "                        amp_s = random.uniform(*cfg.spurious_amp_range) * gain\n",
    "                        sigma_s = float(np.random.uniform(0.25, 2.0))\n",
    "                        tau_s = float(np.random.uniform(cfg.tau_min, cfg.tau_max))\n",
    "                        peaks += emg_peak(molw_base, amp_s, mu, sigma_s, tau_s, left_tail=(random.random() < 0.04))\n",
    "                        evs.append(dict(\n",
    "                            filename=filename, channel=ch_name,\n",
    "                            peak_center_molw=float(mu), peak_height=float(amp_s),\n",
    "                            peak_type=\"spurious\", sigma=float(sigma_s), tau=float(tau_s),\n",
    "                            base_noise=float(st[\"base_noise\"]),\n",
    "                        ))\n",
    "\n",
    "                base_by_ch[ch_name] = base\n",
    "                peaks_by_ch[ch_name] = peaks\n",
    "                sat_levels[ch_name] = st[\"sat\"] * gain\n",
    "                events.extend(evs)\n",
    "\n",
    "            # --- crosstalk on peaks only ---\n",
    "            peaks_ct, used = apply_crosstalk(peaks_by_ch, sat_levels, CT, cfg)\n",
    "\n",
    "            # record crosstalk events (derived from donor peaks)\n",
    "            def can_add_event(chname: str, extra: int = 1) -> bool:\n",
    "                c = sum(1 for e in events if e[\"filename\"] == filename and e[\"channel\"] == chname)\n",
    "                return (c + extra) <= cfg.max_total_events_per_channel\n",
    "\n",
    "            for src, tgt, coef in used:\n",
    "                for e in list(events):\n",
    "                    if e[\"channel\"] != src:\n",
    "                        continue\n",
    "                    amp_ct = float(e[\"peak_height\"]) * abs(float(coef))\n",
    "                    if amp_ct < 8.0:\n",
    "                        continue\n",
    "                    if not can_add_event(tgt, 1):\n",
    "                        continue\n",
    "                    events.append(dict(\n",
    "                        filename=filename, channel=tgt,\n",
    "                        peak_center_molw=float(e[\"peak_center_molw\"]),\n",
    "                        peak_height=float(amp_ct),\n",
    "                        peak_type=\"crosstalk\",\n",
    "                        sigma=float(e.get(\"sigma\", 0.0)),\n",
    "                        tau=float(e.get(\"tau\", 0.0)),\n",
    "                        base_noise=float(e.get(\"base_noise\", 0.0)),\n",
    "                    ))\n",
    "\n",
    "            # --- output dataframe ---\n",
    "            out = tpl.df.copy()\n",
    "            out[\"molw\"] = molw_out\n",
    "\n",
    "            # Ladder\n",
    "            out[\"channel_5\"] = generate_liz500_ladder(molw_base, molw_out, tpl.ladder_noise, mux_shift, cfg).astype(float)\n",
    "\n",
    "            def mu_out(mu: float) -> float:\n",
    "                return float(np.interp(mu, molw_base, molw_out))\n",
    "\n",
    "            # --- build final channels 1..4 with splice+centering ---\n",
    "            for ch in range(1, 5):\n",
    "                ch_name = f\"channel_{ch}\"\n",
    "                st = tpl.stats[ch]\n",
    "\n",
    "                # Full\n",
    "                y_full = base_by_ch[ch_name] + peaks_ct[ch_name]\n",
    "                y_full += add_noise(st[\"base_noise\"], y_full, plant_noise_gain * mux_noise_gain, mode, cfg)\n",
    "                y_full = soft_saturate(y_full, sat_levels[ch_name], cfg.overload_softness)\n",
    "                y_full = shift_series(np.nan_to_num(y_full), mux_shift)\n",
    "                y_out_full = resample_to_molw(molw_base, y_full, molw_out)\n",
    "\n",
    "                # Baseline-only (for <50)\n",
    "                y_pre = base_by_ch[ch_name].copy()\n",
    "                y_pre += add_noise(st[\"base_noise\"], y_pre, plant_noise_gain * mux_noise_gain, mode, cfg)\n",
    "                y_pre = soft_saturate(y_pre, sat_levels[ch_name], cfg.overload_softness)\n",
    "                y_pre = shift_series(np.nan_to_num(y_pre), mux_shift)\n",
    "                y_out_pre = resample_to_molw(molw_base, y_pre, molw_out)\n",
    "\n",
    "                # splice: <50 bp baseline-only\n",
    "                y = np.asarray(y_out_full, float).copy()\n",
    "                y[pre_mask] = np.asarray(y_out_pre, float)[pre_mask]\n",
    "\n",
    "                # baseline centering: constant from <50 region\n",
    "                if cfg.center_baseline:\n",
    "                    y = center_baseline_pre50(y, molw_out, cfg.prepeak_cutoff_bp, cfg.center_q)\n",
    "\n",
    "                out[ch_name] = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0).astype(float)\n",
    "\n",
    "            # Save signals\n",
    "            out.to_csv(os.path.join(signals_dir, filename), sep=\";\", index=False)\n",
    "\n",
    "            # Events on out-axis for masks/centers\n",
    "            events_out = []\n",
    "            for e in events:\n",
    "                eo = dict(e)\n",
    "                eo[\"peak_center_molw\"] = mu_out(float(e[\"peak_center_molw\"]))\n",
    "                events_out.append(eo)\n",
    "\n",
    "            mask_df = build_dense_mask(molw_out, events_out, filename, cfg)\n",
    "            mask_df.insert(0, \"index\", tpl.df[\"index\"].to_numpy(int))\n",
    "            mask_df.to_csv(os.path.join(masks_dir, f\"labels_mask_{mux_name}_{plant_tag}.csv\"), sep=\";\", index=False)\n",
    "\n",
    "            center_df = build_center_labels(molw_out, events_out, filename, cfg)\n",
    "            center_df.insert(0, \"index\", tpl.df[\"index\"].to_numpy(int))\n",
    "            center_df.to_csv(os.path.join(centers_dir, f\"labels_center_{mux_name}_{plant_tag}.csv\"), sep=\";\", index=False)\n",
    "\n",
    "            # labels_map rows\n",
    "            for e in events:\n",
    "                mu_base = float(e[\"peak_center_molw\"])\n",
    "                muo = mu_out(mu_base)\n",
    "                if e[\"channel\"].startswith(\"channel_\") and muo < cfg.prepeak_cutoff_bp:\n",
    "                    continue\n",
    "                if not passes_label_filter(e, cfg):\n",
    "                    continue\n",
    "                labels_map_rows.append(dict(\n",
    "                    filename=e[\"filename\"],\n",
    "                    channel=e[\"channel\"],\n",
    "                    peak_center_molw=float(mu_base),\n",
    "                    peak_center_molw_out=float(muo),\n",
    "                    peak_height=float(e[\"peak_height\"]),\n",
    "                    peak_type=str(e.get(\"peak_type\", \"\")),\n",
    "                    mode=mode,\n",
    "                    mux_shift=mux_shift,\n",
    "                    molw_scale=float(molw_meta[\"molw_scale\"]),\n",
    "                    molw_shift=float(molw_meta[\"molw_shift\"]),\n",
    "                    warp_kind=str(molw_meta[\"warp_kind\"]),\n",
    "                    warp_k=float(molw_meta[\"warp_k\"]),\n",
    "                    molw_jitter_amp=float(molw_meta[\"molw_jitter_amp\"]),\n",
    "                    bp_min_stats=float(cfg.template_stats_min_bp),\n",
    "                    prepeak_cutoff=float(cfg.prepeak_cutoff_bp),\n",
    "                ))\n",
    "\n",
    "            # peak_positions_detailed (legacy): only main/spurious\n",
    "            for e in events:\n",
    "                ch_name = e[\"channel\"]\n",
    "                if ch_name not in (\"channel_1\", \"channel_2\", \"channel_3\", \"channel_4\"):\n",
    "                    continue\n",
    "                ptype = str(e.get(\"peak_type\", \"\"))\n",
    "                if ptype not in (\"true\", \"spurious\"):\n",
    "                    continue\n",
    "\n",
    "                ch_num = int(ch_name.split(\"_\")[1])\n",
    "                muo = mu_out(float(e[\"peak_center_molw\"]))\n",
    "                if muo < cfg.prepeak_cutoff_bp:\n",
    "                    continue\n",
    "\n",
    "                peak_kind = \"main\" if ptype == \"true\" else \"spurious\"\n",
    "                sigma_pb = float(e.get(\"sigma\", 0.0) or 0.0)\n",
    "                peak_width_pb = cfg.legacy_peak_width_mult * sigma_pb\n",
    "                amplitude = float(e.get(\"peak_height\", 0.0) or 0.0)\n",
    "\n",
    "                legacy_rows.append(dict(\n",
    "                    plant_id=plant_id,\n",
    "                    plant_id_str=plant_id_str,\n",
    "                    multiplex=int(mux_idx),\n",
    "                    channel=int(ch_num),\n",
    "                    marker_id=int(ch_num),\n",
    "                    peak_kind=str(peak_kind),\n",
    "                    mu_pb=float(muo),\n",
    "                    sigma_pb=float(sigma_pb),\n",
    "                    peak_width_pb=float(peak_width_pb),\n",
    "                    amplitude=float(amplitude),\n",
    "                    amp_class=(amp_class(amplitude, cfg) if peak_kind == \"main\" else np.nan),\n",
    "                    plant_peak_width_max_pb=float(cfg.legacy_plant_peak_width_max_pb),\n",
    "                ))\n",
    "\n",
    "            # Optional plots\n",
    "            if make_plots:\n",
    "                chan_dir = os.path.join(by_channel_dir, plant_tag, mux_name)\n",
    "                ensure_dir(chan_dir)\n",
    "                for c in range(1, 6):\n",
    "                    plot_channel(out, os.path.join(chan_dir, f\"{mux_name}_{plant_tag}_channel_{c}.png\"),\n",
    "                                 f\"channel_{c}\", cfg.plot_qlo, cfg.plot_qhi)\n",
    "                    done_plots += 1\n",
    "                    progress(done_plots, total_plots)\n",
    "\n",
    "                plot_stacked(out, os.path.join(stacked_dir, f\"{mux_name}_{plant_tag}_STACKED.png\"),\n",
    "                             cfg.plot_qlo, cfg.plot_qhi)\n",
    "                done_plots += 1\n",
    "                progress(done_plots, total_plots)\n",
    "\n",
    "    # Write global files\n",
    "    pd.DataFrame(labels_map_rows).to_csv(os.path.join(map_dir, \"labels_map.csv\"), sep=\";\", index=False)\n",
    "    build_peak_positions_detailed(legacy_rows).to_csv(os.path.join(map_dir, \"peak_positions_detailed.csv\"), index=False)\n",
    "\n",
    "    return dict(\n",
    "        out_dir=out_dir,\n",
    "        signals_dir=signals_dir,\n",
    "        labels_masks_dir=masks_dir,\n",
    "        labels_centers_dir=centers_dir,\n",
    "        labels_map_dir=map_dir,\n",
    "        plots_dir=(plots_root if make_plots else None),\n",
    "    )\n",
    "\n",
    "# =============================================================================\n",
    "# Run section\n",
    "# =============================================================================\n",
    "\n",
    "TEMPLATE_M1 = \"M1_pl1.csv\"\n",
    "TEMPLATE_M2 = \"M2_pl1.csv\"\n",
    "DEFAULT_OUT = \"dataset_synthetic\"\n",
    "\n",
    "try:\n",
    "    n = int(input(\"How many individuals (plants) to generate? [20]: \") or \"20\")\n",
    "except Exception:\n",
    "    n = 20\n",
    "\n",
    "make_plots = (input(\"Generate plots? (y/n) [n]: \").strip().lower() == \"y\")\n",
    "\n",
    "seed_in = input(\"Seed (empty = random): \").strip()\n",
    "seed = int(seed_in) if seed_in else None\n",
    "\n",
    "out_dir = input(f\"Output folder (empty = {DEFAULT_OUT}): \").strip() or DEFAULT_OUT\n",
    "\n",
    "paths = generate_dataset(\n",
    "    template_m1_path=TEMPLATE_M1,\n",
    "    template_m2_path=TEMPLATE_M2,\n",
    "    n_plants=n,\n",
    "    out_dir=out_dir,\n",
    "    cfg=CFG,\n",
    "    make_plots=make_plots,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "for k, v in paths.items():\n",
    "    print(f\"- {k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
